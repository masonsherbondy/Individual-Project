{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2142f108",
   "metadata": {},
   "source": [
    "# IBM Attrition\n",
    "\n",
    "2022.01.24\n",
    "\n",
    "Mason Sherbondy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2767af5b",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "The goal of this project is to develop a machine learning model to use on fictional IBM data to predict employee attrition, that is, whether or not an employee from this fictional data set will leave the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edd512",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "IBM has created a fictional data set based on an employee survey. Employee attrition brings about costs such as business disruption, hiring and training new staff. Exploring this data and testing my models here will give me better insights on how to run through a data set in order to classify records and on what IBM is looking at when considering the likelihood of departure (volunatary or not) of an employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1054964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 61\n",
    "pd.options.display.max_rows = 61\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mason_functions as mf\n",
    "import explore\n",
    "import wrangle\n",
    "import scale \n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66859a2b",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "Many features were discovered to have a relationship with attrition, but none of my models were able to really beat the baseline. I cannot recommend these models for further use, as they could not even beat a simple mode baseline. The best model was a logistic regression model that beat baseline by 2% on the validate set, but only matched the baseline on the test set. Outlier removal or data scaling may have improved my models, but I explored the data for far too long, and so I do not know if these steps may or may not have helped. Features to look out for are: job satisfaction, relationship satisfaction, total working years, distance from home, job level, monthly income, stock option level, technical degree education, sales rep job, lab tech job, being single, overtime and age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a266f9",
   "metadata": {},
   "source": [
    "## Wrangle\n",
    "### Actions taken:\n",
    "* dropped superfluous columns\n",
    "* one-hot encoded categorical features\n",
    "* fixed up column names\n",
    "* reset index to unique employee id\n",
    "* split the data into train, validate and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7da200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
